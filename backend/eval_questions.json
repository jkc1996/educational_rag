[
  {
    "question": "What is the primary goal of the machine learning course described in the document?",
    "answer": "",
    "ground_truth": "The primary goal of the course is to help students develop a theoretical and practical understanding of machine learning principles, enabling them to implement, train, tune, and validate various ML models and apply them to real-world problems in science, engineering, and business.",
    "contexts": [
      "The machine learning course aims to equip students with both theoretical and practical skills in the field of machine learning. It focuses on enabling students to work with real-world datasets, covering essential steps such as data preprocessing, model building, evaluation, and deployment. The curriculum emphasizes critical thinking about trade-offs, including model complexity versus interpretability, the importance of data quality, and ethical considerations in automated decision-making. By the end, students are expected to be proficient in implementing a range of models, including regression, classification, and clustering, using Python-based libraries like scikit-learn and TensorFlow, which are standard in both academia and industry."
    ]
  },
  {
    "question": "What are the main types of machine learning described in the document?",
    "answer": "",
    "ground_truth": "The main types of machine learning are supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.",
    "contexts": [
      "Machine learning is categorized into four primary types based on the nature of the data and the learning process. Supervised learning involves learning from labeled datasets where each input is paired with a corresponding output, used in tasks like spam detection or house price prediction. Unsupervised learning focuses on finding patterns in unlabeled data, applicable to tasks like customer segmentation or topic modeling. Semi-supervised learning combines both labeled and unlabeled data, useful when labeled data is scarce. Reinforcement learning involves learning optimal actions through trial and error with feedback from rewards, commonly used in robotics or game playing."
    ]
  },
  {
    "question": "What is the role of feature selection and engineering in a machine learning system?",
    "answer": "",
    "ground_truth": "Feature selection identifies the most predictive features, while feature engineering creates new features from existing ones to improve model performance, often requiring domain expertise.",
    "contexts": [
      "In a machine learning system, feature selection and engineering are critical steps that enhance model performance by focusing on the most relevant data attributes. Feature selection involves choosing the most predictive features using methods like filter, wrapper, or embedded approaches, reducing noise and computational complexity. Feature engineering, on the other hand, involves creating new features, such as polynomial features or interaction terms, based on domain knowledge to better capture underlying patterns in the data. These processes ensure that the model focuses on meaningful information, improving its predictive power and efficiency."
    ]
  },
  {
    "question": "What is instance-based learning in machine learning?",
    "answer": "",
    "ground_truth": "Instance-based learning, also known as memory-based or lazy learning, is a machine learning approach where the algorithm stores the training data and makes predictions for new inputs by comparing them to stored examples, typically using similarity measures, without building an explicit model during training.",
    "contexts": [
      "Instance-based learning, often called memory-based or lazy learning, contrasts with model-based approaches by not learning a global function or parameters during training. Instead, it stores the raw training examples and uses them directly at prediction time to estimate outputs for new queries based on their similarity to stored instances. This method assumes that similar inputs have similar outputs, making it highly flexible but sensitive to noise and outliers. It is computationally efficient during training but can be slow during prediction, especially for large datasets."
    ]
  },
  {
    "question": "How does the k-Nearest Neighbor (k-NN) algorithm work for classification?",
    "answer": "",
    "ground_truth": "The k-Nearest Neighbor (k-NN) algorithm for classification predicts the class of a new input by finding the k closest training examples based on a distance metric, typically Euclidean distance, and assigning the class that is most common among these neighbors.",
    "contexts": [
      "The k-NN algorithm is a simple yet effective instance-based learning method used for classification and regression. For classification, it identifies the k nearest training points to a new input using a distance metric, such as Euclidean distance, and assigns the class that appears most frequently among these neighbors. The choice of k and the distance metric significantly impacts performance, with small k values being sensitive to noise and large k values potentially overlooking local patterns. Feature scaling and selection are crucial to ensure fair distance calculations."
    ]
  },
  {
    "question": "What is the main idea behind Locally Weighted Regression (LWR)?",
    "answer": "",
    "ground_truth": "Locally Weighted Regression (LWR) fits a unique, local regression model for each query point by assigning weights to training examples based on their proximity to the query, typically using a kernel function, allowing it to capture complex, nonlinear trends in the data.",
    "contexts": [
      "Locally Weighted Regression (LWR) is an instance-based method that excels at modeling nonlinear relationships in regression tasks. For each new input, LWR assigns weights to training points based on their distance from the query, often using a Gaussian kernel, and fits a weighted least squares model. The kernel bandwidth controls the locality of the fit, with smaller bandwidths focusing on local patterns and larger ones behaving more like global regression. This approach is computationally intensive but highly interpretable and flexible for capturing local trends."
    ]
  }
]
